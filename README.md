# EC601_Project
### Project 1: Brief Report on Natural Language Processing with Feedback (13)
#### Project Statement/ Applications
The project is based on an ongoing Kaggle competition (https://www.kaggle.com/competitions/feedback-prize-english-language-learning) to develop a natural language processing platform that will assess English writing skills of 8-12th grade English Language Learners (ELL). With globalization of society, English has risen as the global language that is learned by millions of people around the world and it is evermore critical to learn English to be able to communicate internationally, whether for personal or work reasons. However, there is also a severe lack of able teachers who can provide constructive feedback to many of the ELLs or the teachers who may be able to help might not be accessible for many learners [1].

Currently, there are existing tools to provide feedback to writing samples, but the feedback doesn't take into account of the writer's English proficiency, making the feedback biased against some learners more [1]. Because the writers are still in the process of learning, it is essential to be able to provide useful feedback that they can learn from, rather than overly negative feedback that may discourage the writer from continuing to learn. If the platform is successfully implemented, it can aid teachers to provide initial feedback that can then be used as basis for the final feedback, making the overall grading process proceed faster. Eventually, it could also be implemented in giving more robust feedback through online portals or other programs and helping millions around the world access a useful educational platform. 

The evaluation metrics vary from cohesion, syntax, vocabulary, phraseology, grammar, and use of conventions, each in range from 1.0 to 5.0, at an increment of 0.5. The essays are already graded by human graders and the goal of the project is to train natural language processing models to get as close as possible to those feedback values while taking into account the writer's detected English abilities [1]. 


#### Literature Review
Automated feedback using natural language processing has slowly moved forward, since its rough conception in the 1960s by the Project Essay Grade (PEG) system [2]. Having a robust automated platform is especially of interest in the educational sector and with rise of newer natural language processing platforms, such as RNN (Recurrent Neural Networks), LSTM (Long Short-Term Memory), and most recently the Tranformer models, having such a platform at a manageable computational cost is a possbility. 
In general sense, a NLP model can score using various criteria. Some features that a model can use might include Lexical Diversity, given by instances of unique words within the text, or Word Frequency, given by how common the words are in general English vocabulary, or Syntactical Complexity, given by how complex sentences may be structured, or Syntatic Similarity, given by how similar level structures are within text, or Lexical Overlap, given by how words are reused within text to aid in comprehension, or Semantic Overlap, given by semantics overlap within text [3]. Other criteria can be also incorporated, another 

#### Open Source Research 

#### Conclusion

#### References
[1] Kaggle: Feedback Prize - English Language Learning (https://www.kaggle.com/competitions/feedback-prize-english-language-learning)
[2] Ludwig et al. Automated Essay Scoring Using Transformer Models. https://arxiv.org/pdf/2110.06874.pdf
[3] Ghanta. Automated Essay Evaluation Using Natural Language Processing and Machine Learning and Machine Learning. https://csuepress.columbusstate.edu/cgi/viewcontent.cgi?article=1330&context=theses_dissertations
[4] Ormerod et al. Automated essay scoring using efficient transformer-based language models. https://arxiv.org/pdf/2102.13136.pdf


